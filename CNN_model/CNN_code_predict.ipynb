{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 39, 1291, 16)      80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 19, 645, 16)       0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 19, 645, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 18, 644, 32)       2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 9, 322, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 9, 322, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 321, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 4, 160, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 4, 160, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 3, 159, 128)       32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 1, 79, 128)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1, 79, 128)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 44,086\n",
      "Trainable params: 44,086\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(\"CNN_code_model.h5\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(file_name):\n",
    "    X, sample_rate = librosa.load(file_name)\n",
    "    mfccs = librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40)\n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mAnnotatedAudioFiles\u001b[0m/\r\n",
      "\u001b[01;34mAnnotatedAudioFiles_tmp\u001b[0m/\r\n",
      "\u001b[01;34mCNN_all\u001b[0m/\r\n",
      "CNN_all_classification_model.ipynb\r\n",
      "CNN_all_model.h5\r\n",
      "CNN_all_preprocessing.ipynb\r\n",
      "CNN_code_classification_model.ipynb\r\n",
      "CNN_code_model.h5\r\n",
      "CNN_code_predict.ipynb\r\n",
      "CNN_event_classification_model.ipynb\r\n",
      "CNN_event_preprocessing.ipynb\r\n",
      "CNN_model.h5\r\n",
      "\u001b[01;34mCNN_predict_data\u001b[0m/\r\n",
      "CNN_situation_classification_model.ipynb\r\n",
      "CNN_situation_predict.ipynb\r\n",
      "CNN_situation_preprocessing.ipynb\r\n",
      "KNN_binary_classification.ipynb\r\n",
      "KNN_code_classification.ipynb\r\n",
      "KNN_event_classification.ipynb\r\n",
      "KNN_predict.ipynb\r\n",
      "KNN_situation_classification.ipynb\r\n",
      "Untitled-Copy1.ipynb\r\n",
      "Untitled.ipynb\r\n",
      "Untitled1.ipynb\r\n",
      "Untitled2.ipynb\r\n",
      "Untitled3.ipynb\r\n",
      "binary_classification.ipynb\r\n",
      "convert_mp3_to_wav.ipynb\r\n",
      "\u001b[01;34mconvert_wav\u001b[0m/\r\n",
      "convert_wav.ipynb\r\n",
      "convert_wav_final.ipynb\r\n",
      "crop_event.ipynb\r\n",
      "crop_wav.ipynb\r\n",
      "cut_file.wav\r\n",
      "\u001b[01;34mdata\u001b[0m/\r\n",
      "data_preprocessing.ipynb\r\n",
      "dataframe_add_file_name.ipynb\r\n",
      "event_data_preprocesssing.csv\r\n",
      "event_data_preprocesssing_final.csv\r\n",
      "event_data_preprocesssing_jjin_real_final.csv\r\n",
      "event_data_preprocesssing_real_final.csv\r\n",
      "\u001b[01;34mffmpeg-4.4.1-amd64-static\u001b[0m/\r\n",
      "knn_binary_model.pkl\r\n",
      "knn_code_model.pkl\r\n",
      "knn_model.pkl\r\n",
      "knn_situation_model.pkl\r\n",
      "model_classification2.ipynb\r\n",
      "raw_data.ipynb\r\n",
      "same_crop_wav.ipynb\r\n",
      "\u001b[01;34msame_sound_extract\u001b[0m/\r\n",
      "\u001b[01;34msound_extract\u001b[0m/\r\n",
      "star_pydub.ipynb\r\n",
      "test.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.2899487e+02, -5.2899487e+02, -5.2564697e+02, ...,\n",
       "        -2.1546034e+02, -2.3469844e+02, -2.4204639e+02],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  4.6393204e+00, ...,\n",
       "         1.3780266e+02,  1.2830196e+02,  1.3664249e+02],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  4.3624334e+00, ...,\n",
       "        -1.2969001e+01, -4.4036245e+00, -7.2050619e+00],\n",
       "       ...,\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  3.2161161e-01, ...,\n",
       "         5.1554346e+00,  9.1413536e+00,  2.7488253e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  4.3222263e-01, ...,\n",
       "        -3.5348375e+00, -6.5571308e+00, -2.0395958e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  4.6939585e-01, ...,\n",
       "        -8.3651543e+00, -1.4543214e+01, -1.1859083e+01]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = extract_feature(\"CNN_predict_data/crop_data/음성 012.wav\")\n",
    "x = np.array(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 40, 1292, 1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.reshape(-1, x.shape[0], x.shape[1], 1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9619079e-01, 8.6034539e-09, 3.8078520e-03, 1.3633515e-06,\n",
       "        1.3233645e-09, 1.9160083e-11]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = model.predict(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = np.argmax(y)\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "violence\n"
     ]
    }
   ],
   "source": [
    "if label > 0:\n",
    "    print(\"normal\")\n",
    "else:\n",
    "    print(\"violence\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
